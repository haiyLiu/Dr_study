# Representation Learning表征学习

表征学习 或 特征学习是学习一个特征的技术集合，将原始数据转换为能够被机器学习有效开发的某种形式，并且尽可能的保留原始数据所携带的信息。允许计算机学习使用特征的同时，也学习如何提取特征：学习如何学习。



# ML和DL的区别

假设现在有一个分类任务，系统必须识别给的图片是猫还是狗。

如果我们将此作为一个ML问题，我们必须定义一系列对分类结果有影响的特征向量，诸如动物是否有胡须等。

而DL会**自动**找出这些对分类很重要的特征。



# mention

提及（mention）是实体在具体上下文中的一段指代。



# Coarse-grained Entity Typing

粗粒度实体分类。

将文本中的提及抽取出来，并判断其在上下文中的类型，通常为 人(person)，位置(location)等粗粒度。



# Fine-grained Entity Typing

细粒度实体分类。

在给定提及的情况下，依据上下文给提及赋予一个或多个实体类型，提及的类型将会更加细致。而且会形成一个类型树，比如actor（男演员）是person（人）的子类型，airport（机场）是facility（人造设施）的子类型。

![img](https://pic4.zhimg.com/v2-f001566662999321a4822a12ba73dcdf_r.jpg)









# Zero-shot learning

零样本学习就是：在测试集中，有些类别不在训练集中，利用训练集得到的模型，使之应用到测试集能正确识别那些在训练集中不存在的标签。



# 打开Jupyter

```
# 打开terminal
> jupyter notebook
```



# pip install git+

pip install git+https://github.com/openai/CLIP.git

假如有一个setup.py文件，位置在git上，我希望一次性安装到位，而不是先git clone，再转到对应的目录，进行安装。

通常的安装

```
git clone http://127.0.0.1/xxx/demo.git
cd demo
python setup.py install
```

简便式安装

```
pip install git+http://127.0.0.1/xxx/demo.git
```



# Shell脚本

| 名称 | 含义                                                         |
| ---- | ------------------------------------------------------------ |
| $#   | 传给脚本的参数个数                                           |
| $0   | 脚本本身的名字                                               |
| $1   | 传递给脚本的第一个参数                                       |
| $2   | 传递给脚本的第二个参数                                       |
| $@   | 传给脚本的所有参数的列表                                     |
| $*   | 以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个 |
| $$   | 脚本运行的当前进程ID号                                       |
| $?   | 显示最后命令的退出状态，0表示没有错误，其他表示有错误        |







# Torch 、torchvision 、Python 版本对应关系以及安装 GPU 或 CPU 版本的 pytorch

https://blog.csdn.net/qq_40630902/article/details/118356845#:~:text=1.%20torch%20-%20torchvision%20-%20python%20%E7%89%88%E6%9C%AC%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%20%E4%BB%8E%E8%A1%A8%E4%B8%AD%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%87%BA%EF%BC%8C%E5%9C%A8%E4%BD%BF%E7%94%A8,%E6%9C%80%E4%B8%BA%E5%90%88%E9%80%82%EF%BC%8C%E5%BD%93%E7%84%B6%E6%9C%80%E5%A5%BD%E8%BF%98%E6%98%AF%E6%A0%B9%E6%8D%AE%E4%BD%A0%E8%87%AA%E5%B7%B1%E7%9A%84%E9%9C%80%E8%A6%81%E9%80%89%E6%8B%A9%20python%20%E7%89%88%E6%9C%AC%E3%80%82%20conda%20create%20-n%20%E7%8E%AF%E5%A2%83%E7%9A%84%E5%90%8D%E5%AD%97%20python%3D3.7



# Pyenv使用

## 创建虚拟环境

```
pyenv virtualenv python版本 虚拟环境名

例如：
pyenv virtualenv 3.6.5 python3.6
```



## 激活虚拟环境

### 修改环境变量 

```
vim ~/.zshrc
```

```
export PYENV_ROOT="/Users/liuhaiyan/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"
if command -v pyenv 1>/dev/null 2>&1; then
 eval "$(pyenv init -)"
fi
```

```
source ~/.zshrc
```

### 激活环境

```
pyenv activate 虚拟环境名
```



### 删除虚拟环境

```
rm -rf ~/.pyenv/versions/python版本/envs/环境名
```



## 退出虚拟环境

```
pyenv deactivate
```



## 查看所有的虚拟环境

```
pyenv virtualenvs
```



## 查看当前安装的全部python版本

```
pyenv versions
```



# 删除重复的环境变量

```
export PATH=$(echo $PATH | tr : "\n"| sort | uniq | tr "\n" :)
```





# Mac删除path中的环境变量

要删除第三处的冗余路径：

-f1,2,4-的意思是只保留开头1，2，以及从4到最后的变量

如果要删除第8个，则使用-f1,2,3,4,5,6,7,9-

```
export PATH=`echo $PATH | cut -d":" -f1,2,4-` 
```



# Python

## transforms函数

### Compose

将多个transformer操作整合在一起。

```
transforms.Compose([
    transforms.CenterCrop(10),
    transforms.ToTensor(),
])
```



### Resize

将给定的图片resize到指定的size。

```
transforms.Resize(x) #将图片短边缩放至x，长宽比保持不变
```

```
transforms.Resize([h, w]) #指定宽和高
```



### Normalize

对图像的每个channel进行标准化（均值变为0，标准差变为1），可以加快模型的收敛。

```
transforms.normalize(mean_vals,std_vals)
```

mean 和 std 肯定要在normalize（）之前自己先算好再传进去的，不然每次normalize（）就得把所有的图片都读取一遍算这两个。



### ToTensor

把PIL.Image或ndarray从 (H x W x C)形状转换为 (C x H x W) 的tensor。

```
transforms.ToTensor()
```



### CenterCrop

从图片中心开始沿两边裁剪，裁剪后的图片大小为（size*size）

```
transforms.CenterCrop(size)
```



### RandomCrop

```
transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant')
size：期望随机裁剪之后输出的尺寸
padding：填充边界的值，单个（int）,两个（[左/右，上/下]），四个（各个边界）
pad_if_needed :bool值，避免数组越界
fill:填充
padding_mode ：填充模式
  “constant”:利用常值进行填充
  “edge”:利用图像边缘像素点进行填充
  “reflect”：利用反射的方式进行填充[1, 2, 3, 4] 》[3, 2, 1, 2, 3, 4, 3, 2]
  “symmetric”：对称填充方法[1, 2, 3, 4] 》》[2, 1, 1, 2, 3, 4, 4, 3]
```



### FiveCrop

在原图片的四个角和中心处各截取一个大小为size的图片

```
transforms.FiveCrop(size)
```



### TenCrop

transforms.TenCrop 就是在 transforms.FiveCrop 基础上再进行水平或者竖直翻转（Flip），默认为水平翻转。

```
transforms.TenCrop(size, vertical_flip=False)
```



### RandomResizedCrop

先随意裁剪出一个随机大小和宽高比的图片，再对该图片进行Resize操作，变为size*size大小。

```
transforms.RandomResizedCrop(size)
```



## PIL

PIL（图像处理库）来实现不同图像格式的转换，其中PIL的九种不同模式：1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。

- 模式“1”为二值图像，非黑即白。但是它每个像素用8个bit表示，0表示黑，255表示白。

- 模式“L”为灰色图像，它的每个像素用8个bit表示，0表示黑，255表示白，其他数字表示不同的灰度。在PIL中，从模式“RGB”转换为“L”模式是按照下面的公式转换的：
  $$
  L=R\times\frac{299}{1000}+G\times\frac{587}{1000}+B\times\frac{114}{1000}
  $$

- 模式“P”为8位彩色图像，它的每个像素用8个bit表示，其对应的彩色值是按照调色板查询出来的。

- 模式“RGBA”为32位彩色图像，它的每个像素用32个bit表示，其中24bit表示红色、绿色和蓝色三个通道，另外8bit表示alpha通道，即透明通道。

- 模式“CMYK”为32位彩色图像，它的每个像素用32个bit表示。模式“CMYK”就是印刷四分色模式，它是彩色印刷时采用的一种套色模式，利用色料的三原色混色原理，加上黑色油墨，共计四种颜色混合叠加，形成所谓“全彩印刷”。C：Cyan = 青色，又称为‘天蓝色’或是‘湛蓝’M：Magenta = 品红色，又称为‘洋红色’；Y：Yellow = 黄色；K：Key Plate(blacK) = 定位套版色（黑色）

- 模式“YCbCr”为24位彩色图像，它的每个像素用24个bit表示。YCbCr其中Y是指亮度分量，Cb指蓝色色度分量，而Cr指红色色度分量。人的肉眼对视频的Y分量更敏感，因此在通过对色度分量进行子采样来减少色度分量后，肉眼将察觉不到的图像质量的变化。

- 模式“I”为32位整型灰色图像，它的每个像素用32个bit表示，0表示黑，255表示白，(0,255)之间的数字表示不同的灰度。

- 模式“F”为32位浮点灰色图像，它的每个像素用32个bit表示，0表示黑，255表示白，(0,255)之间的数字表示不同的灰度。

### Image

#### convert



## os.listdir()

返回指定的路径下包含的文件或文件夹的名字的列表。

```
os.listdir(path)
```



# [torch](https://so.csdn.net/so/search?q=torch&spm=1001.2101.3001.7020).utils.data

```
 1. epoch：所有的训练样本输入到模型中称为一个epoch； 
 2. iteration：一批样本输入到模型中，成为一个Iteration;
 3. batchszie：批大小，决定一个epoch有多少个Iteration；
 4. 迭代次数（iteration）=样本总数（epoch）/批尺寸（batchszie）
 5. dataset (Dataset) – 决定数据从哪读取或者从何读取；
 6. batch_size (python:int, optional) – 批尺寸(每次训练样本个数,默认为１）
 7. shuffle (bool, optional) –每一个 epoch是否为乱序 (default: False)；
 8. num_workers (python:int, optional) – 是否多进程读取数据（默认为０);
 9. drop_last (bool, optional) – 当样本数不能被batchsize整除时，最后一批数据是否舍弃（default: False)
 10. pin_memory（bool, optional) - 如果为True会将数据放置到GPU上去（默认为false） 
```



### Dataset类

`torch.utils.data.Dataset`是代表自定义数据集方法的类，用户可以通过继承该类来自定义自己的数据集类，在继承时要求用户重载`__len__()`和`__getitem__()`这两个方法。

- `__len__()`：**返回的是数据集的大小**。我们构建的数据集是一个对象，而数据集不像序列类型（列表、元组、字符串）那样可以直接用`len()`来获取序列的长度，魔法方法`__len__()`的目的就是方便像序列那样直接获取对象的长度。如果`A`是一个类，`a`是类`A`的实例化对象，当`A`中定义了魔法方法`__len__()`，`len(a)`则返回对象的大小。
- `__getitem__()`：**实现索引数据集中的某一个数据**。我们知道，序列可以通过索引的方法获取序列中的任意元素，`__getitem__()`则实现了能够通过索引的方法获取对象中的任意元素。此外，我们可以在`__getitem__()`中**实现数据预处理**。

### DataLoader类

**作用**

- `DataLoader`将`Dataset`对象或自定义数据类的对象封装成一个迭代器；
- 这个迭代器可以迭代输出`Dataset`的内容；
- 同时可以实现多进程、shuffle、不同采样策略，数据校对等等处理过程。



**返回值**

dataloader返回dataset中\__getitem__()方法return的值。



`__init__()`中的几个重要的输入：

- `dataset`：这个就是pytorch已有的数据读取接口（比如torchvision.datasets.ImageFolder）或者自定义的数据接口的输出，该输出要么是torch.utils.data.Dataset类的对象，要么是继承自torch.utils.data.Dataset类的自定义类的对象。
- `batch_size`：根据具体情况设置即可。
- `shuffle`：bool型，随机打乱顺序，一般在训练数据中会采用。
- `collate_fn`：从dataset 获取一个batch 数据后，对这批数据进行处理的函数。
- `batch_sampler`：从注释可以看出，其和batch_size、shuffle等参数是互斥的，一般采用默认。
- `sampler`：其和shuffle是互斥的，一般默认即可。
- `num_workers`：这个参数必须大于等于0，0的话表示数据导入在主进程中进行，其他大于0的数表示通过多个进程来导入数据，可以加快数据导入速度。
- `pin_memory`：pin_memory (bool, optional): If True, the data loader will copy tensors into CUDA pinned memory before returning them。
- `timeout`：是用来设置数据读取的超时时间的，但超过这个时间还没读取到数据的话就会报错。
- `drop_last`：`drop_last=True`时会丢弃数据集最后一个长度不能被batch大小整除的批次，在`drop_last=False`时保留最后一个批次。



### Random_split()

随机将一个数据集划分成给定长度的**不重叠**的新数据集。

```
torch.utils.data.random_split(dataset, lengths, generator=<torch._C.Generator object>)

***参数***
dataset——要划分的数据集
lengths——要划分的长度
generator——用于随机排列的生成器
```

```
import torch
from torch.utils.data import random_split

dataset = range(10)
train_dataset, test_dataset = random_split(
    dataset=dataset,
    lengths=[7, 3],
    generator=torch.Generator().manual_seed(0)
)
print(list(train_dataset))
print(list(test_dataset))

# output
[4, 1, 7, 5, 3, 9, 0]
[8, 6, 2]
```



## RandomSampler()

```
RandomSampler(data_source, replacement=False, num_samples=None, generator=None)

***功能***
对样本进行采样

***参数***
data_source——被采样的数据集合
replacement——若为True，即可重复对一个样本进行采样；若为False，即一个样本最多只能被采样一次
num_samples——所采样本的数量，默认采全部样本。当replacement=True时，可指定采样数量，即修改num_samples的大小；当replacement=False时，不可指定num_samples
generator——采样过程中的生成器
```

```
from torch.utils.data import RandomSampler

sampler_t = RandomSampler(range(20), replacement=True)
sampler_f = RandomSampler(range(20), replacement=False)
sampler_t_8 = RandomSampler(range(20), replacement=True, num_samples=8)
print('sampler_t:', [i for i in sampler_t])
print('sampler_f:', [i for i in sampler_f])
print('sampler_t_8:', [i for i in sampler_t_8])

#output
# replacement设为True时，会对同一样本多次采样
sampler_t: [7, 3, 13, 17, 4, 5, 8, 18, 15, 8, 1, 3, 17, 4, 13, 13, 16, 14, 15, 11]
# 相当于打乱了0～19集合的顺序
sampler_f: [3, 5, 19, 10, 6, 7, 13, 16, 15, 9, 14, 0, 4, 18, 12, 2, 11, 17, 1, 8]
# replacement设为True时，可以规定采样数量，如这里只采8个
sampler_t_8: [1, 9, 4, 5, 11, 18, 18, 4]
```



## torch.nn.utils.rnn

### pad_sequence()

pad_sequence 是对[tensor](https://so.csdn.net/so/search?q=tensor&spm=1001.2101.3001.7020)做padding 的

**应用场景**

当我们有多个矩阵，只有第一个矩阵的维度和其他矩阵的维度不同，此时我们希望将它们作为NN的input，但是NN要求input都是定长的，所以需要对input进行统一维度处理。

```
torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0)

batch_first=True 第一个维度是batch_size
```



## dict类

### keys()

获取字典的所有key。

```
dict.keys()
```



### values()

获取字典的所有value。

```
dict.values()
```



### items()

获取key值，value值。

```
for key,value in dict.items():
	print(key,value)
```



## list类

### len()

获取长度。

```
len(list)
```



## tensor类

### permute()

将tensor的维度换位。

```
tensor.permute(*dims)


>>> x = torch.randn(2, 3, 5) 
>>> x.size() 
torch.Size([2, 3, 5]) 
>>> x.permute(2, 0, 1).size() 
torch.Size([5, 2, 3])
```



### transpose()

transpose()一次只能在两个维度间进行转置。

```
tensor.transpose(dim0, dim1)
```

