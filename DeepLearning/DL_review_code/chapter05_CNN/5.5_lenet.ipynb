{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 卷积神经网络 LeNet\n",
    "    -与多层感知机对比（图像分类任务）。在多层感知机中，每张图像的高和宽是28像素，将图像中的像素逐行展开，得到长度为784的向量，输入到全连接层中。\n",
    "        缺点：\n",
    "        *图像在同一列邻近的像素在这个向量中可能相距较远，相关性不能被模型很好的学习。\n",
    "        *对于大尺寸图像，系统开销很大。\n",
    "    -卷积层\n",
    "        *卷积层保留了图像的形状，使图像像素在高和宽两个方向上的相关性能被有效识别；\n",
    "        *卷积层通过滑动窗口使同一卷积核与不同位置的输入重复计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5.1 LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): Sigmoid()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channels, out_channels, kernel_size\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),   #值域变为0-1\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "net = LeNet()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5.2 获取数据和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "epoch 1, loss 2.3055, train acc 0.098, test acc 0.100, time 12.0 sec\n",
      "epoch 2, loss 2.2791, train acc 0.180, test acc 0.342, time 2.2 sec\n",
      "epoch 3, loss 1.9809, train acc 0.332, test acc 0.463, time 2.3 sec\n",
      "epoch 4, loss 1.5370, train acc 0.476, test acc 0.539, time 2.2 sec\n",
      "epoch 5, loss 1.2828, train acc 0.553, test acc 0.562, time 2.2 sec\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "batch_size = 256\n",
    "train_data = torchvision.datasets.FashionMNIST(root='../Datasets/', train=False, transform=transforms.ToTensor())\n",
    "test_data = torchvision.datasets.FashionMNIST(root='../Datasets/', train=False, transform=transforms.ToTensor())\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)\n",
    "\n",
    "def evaluate_acccuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, nn.Module):\n",
    "        device = list(net.parameters())[0].device\n",
    "    \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().item()\n",
    "                net.train()\n",
    "            else:   # 自定义的模型\n",
    "                if 'is_training' in net.__code__.co_varnames:\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().cpu().item()\n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print('training on', device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_acccuracy(test_iter, net, device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "\n",
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_review_code-arXkr9ho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
