{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.7.2 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import zipfile\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    \"\"\"加载周杰伦歌词数据集\"\"\"\n",
    "    with zipfile.ZipFile('../Datasets/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n",
    "\n",
    "(corpus_indices, char_to_idx, idx_to_char, vocab_size) = load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.7.3 从零开始实现GRU\n",
    "    6.7.3.1 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print('Will use', device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "    \n",
    "    def _three():\n",
    "        return (\n",
    "            _one((num_inputs, num_hiddens)),\n",
    "            _one((num_hiddens, num_hiddens)),\n",
    "            torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True)\n",
    "        )\n",
    "    \n",
    "    W_xz, W_hz, b_z = _three()\n",
    "    W_xr, W_hr, b_r = _three()\n",
    "    W_xh, W_hh, b_h = _three()\n",
    "\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)\n",
    "    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.7.3.2 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(inputs, state, params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)\n",
    "        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)\n",
    "        H_tilda = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(R * H, W_hh) + b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.7.3.3 训练模型并创作歌词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, perplexity 148.002437, time 0.40 sec\n",
      " - 分开 我想你的让我 你想我想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想\n",
      " - 不分开 我想你的让我 你想我想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想想\n",
      "epoch 80, perplexity 30.565626, time 0.37 sec\n",
      " - 分开 我想要你的微笑 我想你这样 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想\n",
      " - 不分开  没有你在我有 有你的话笑 我想要你的微笑 我想你这样 我不要再想 我不要再想 我不要再想 我不要\n",
      "epoch 120, perplexity 5.716406, time 0.36 sec\n",
      " - 分开 我想就这样牵着你的手不放开 爱可不可以简简单单没有伤害 你 靠着我的肩膀 你 在我胸口睡著 像这样\n",
      " - 不分开我 你不再 不知我 不要我 说你怎么对我 别发抖 快给我抬起头 有话去对医药箱说 别怪我 别怪我 说\n",
      "epoch 160, perplexity 1.773227, time 0.39 sec\n",
      " - 分开 这小的梦猫 喜欢它 瞎念常 有属于  有漠么么对着我有攻  说说了飞 我有多烦恼 我想要你的微笑每\n",
      " - 不分开不远 这小我的泪是就 说通 在又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 不想太多 我想一定\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n",
    "d2l.train_and_predict_rnn(gru, get_params, init_gru_state, num_hiddens, vocab_size,\n",
    "                          device, corpus_indices, idx_to_char, char_to_idx, False,\n",
    "                          num_epochs, num_steps, lr, clipping_theta, batch_size,pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, perplexity 1.017083, time 0.05 sec\n",
      " - 分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 不想太多 我想一定是我听错弄错搞\n",
      " - 不分开始 担心今天的你过得好不好 整个画面是你 想你想的睡不著 嘴嘟嘟那可爱的模样 还有在你身上香香的味道\n",
      "epoch 80, perplexity 1.011029, time 0.06 sec\n",
      " - 分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 不想太多 我想一定是我听错弄错搞\n",
      " - 不分开球 已经不是你 那场悲剧 是你完美演出的一场戏 宁愿心碎哭泣 再狠狠忘记 你爱过我的证据 让晶莹的泪\n",
      "epoch 120, perplexity 1.007677, time 0.05 sec\n",
      " - 分开的手不放开 爱能不能够永远单纯没有悲哀 我 想带你骑单车 我 想和你看棒球 想这样没担忧 唱着歌 一\n",
      " - 不分开 如果我遇见你是一场悲剧 我想我这辈子注定一个人演戏 最后再一个人慢慢的回忆 没有了过去 我将往事抽\n",
      "epoch 160, perplexity 1.008421, time 0.05 sec\n",
      " - 分开 我想就这样牵着你的手不放开 爱能不能够永远单纯没有悲哀 我 想带你骑单车 我 想和你看棒球 想这样\n",
      " - 不分开  有知不觉  已经不是我 上海一九四三 泛黄的春联还残无力的躺在干枯的河 在等待雨季来临变沼泽 灰\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)\n",
    "model = d2l.RNNModel(gru_layer, vocab_size).to(device)\n",
    "d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n",
    "                                corpus_indices, idx_to_char, char_to_idx,\n",
    "                                num_epochs, num_steps, lr, clipping_theta,\n",
    "                                batch_size, pred_period, pred_len, prefixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_review_code-arXkr9ho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
